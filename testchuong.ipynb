{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09153f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 10:19:16.639683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f14ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATITUDE = 16.0471       # vÃ­ dá»¥: ÄÃ  Náºµng\n",
    "LONGITUDE = 108.2068\n",
    "MODEL_PATH = \"hybrid_cnn_lstm_weather.keras\"  # mÃ´ hÃ¬nh báº¡n Ä‘Ã£ train\n",
    "SCALER_PATH = \"scaler.joblib\"                 # scaler Ä‘Ã£ lÆ°u khi train\n",
    "INPUT_LEN = 24 * 7       # 7 ngÃ y Ä‘áº§u vÃ o\n",
    "OUTPUT_LEN = 24          # model dá»± bÃ¡o 24 giá» tá»›i (1 ngÃ y)\n",
    "FEATURES = [\n",
    "    \"T2M\",\"QV2M\",\"PS\",\"WS10M\",\n",
    "    \"PRECTOTCORR\",\"CLRSKY_SFC_SW_DWN\",\n",
    "    \"hour\",\"day\",\"month\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cd509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasa_power_hourly(lat, lon, start_date, end_date):\n",
    "    params = [\"T2M\",\"QV2M\",\"PS\",\"WS10M\",\"PRECTOTCORR\",\"CLRSKY_SFC_SW_DWN\"]\n",
    "    url = (\n",
    "        f\"https://power.larc.nasa.gov/api/temporal/hourly/point?\"\n",
    "        f\"parameters={','.join(params)}&community=RE\"\n",
    "        f\"&longitude={lon}&latitude={lat}\"\n",
    "        f\"&start={start_date.strftime('%Y%m%d')}\"\n",
    "        f\"&end={end_date.strftime('%Y%m%d')}\"\n",
    "        f\"&format=JSON\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"properties\"][\"parameter\"]\n",
    "\n",
    "    timestamps = [pd.to_datetime(t, format=\"%Y%m%d%H\") for t in data[\"T2M\"].keys()]\n",
    "    df = pd.DataFrame({\"date\": timestamps})\n",
    "    for p in params:\n",
    "        df[p] = list(data[p].values())\n",
    "\n",
    "    # ThÃªm Ä‘áº·c trÆ°ng phá»¥ trá»£\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"day\"] = df[\"date\"].dt.day\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"Latitude\"] = lat\n",
    "    df[\"Longitude\"] = lon\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae70de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, scaler=None):\n",
    "    df = df.copy()\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        df[FEATURES] = scaler.fit_transform(df[FEATURES])\n",
    "    else:\n",
    "        df[FEATURES] = scaler.transform(df[FEATURES])\n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9961382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_sequence(df):\n",
    "    arr = df[FEATURES].values.astype(\"float32\")\n",
    "    X = arr[-INPUT_LEN:]              # láº¥y 7 ngÃ y gáº§n nháº¥t\n",
    "    return np.expand_dims(X, axis=0)  # (1, INPUT_LEN, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4fcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_T2M():\n",
    "    print(\"ðŸ“¡ Äang táº£i dá»¯ liá»‡u NASA POWER...\")\n",
    "    end_date = dt.datetime.utcnow()\n",
    "    start_date = end_date - dt.timedelta(days=45)\n",
    "    df = get_nasa_power_hourly(LATITUDE, LONGITUDE, start_date, end_date)\n",
    "    print(\"âœ… Dá»¯ liá»‡u NASA:\", df.shape)\n",
    "\n",
    "    # Load scaler\n",
    "    try:\n",
    "        scaler = joblib.load(SCALER_PATH)\n",
    "        print(\"ðŸ“¦ ÄÃ£ load scaler huáº¥n luyá»‡n.\")\n",
    "    except:\n",
    "        print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y scaler, sáº½ fit táº¡m thá»i.\")\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df[FEATURES])\n",
    "\n",
    "    # Scale & táº¡o input\n",
    "    df_scaled, _ = preprocess_features(df, scaler)\n",
    "    X_input = make_input_sequence(df_scaled)\n",
    "\n",
    "    # Load model\n",
    "    print(\"ðŸ§  Äang táº£i mÃ´ hÃ¬nh:\", MODEL_PATH)\n",
    "    model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # Dá»± bÃ¡o\n",
    "    print(\"ðŸ¤– Äang dá»± bÃ¡o 24 giá» tá»›i (T2M)...\")\n",
    "    y_pred = model.predict(X_input)[0]  # (24,)\n",
    "    dummy = np.zeros((len(y_pred), len(FEATURES)))\n",
    "    dummy[:, 0] = y_pred                # chá»‰ cá»™t T2M\n",
    "    y_pred_inverse = scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "    # Táº¡o thá»i gian tÆ°Æ¡ng lai\n",
    "    last_date = df[\"date\"].iloc[-1]\n",
    "    future_dates = [last_date + dt.timedelta(hours=i+1) for i in range(len(y_pred_inverse))]\n",
    "\n",
    "    # DataFrame káº¿t quáº£\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"date\": future_dates,\n",
    "        \"T2M_predicted\": y_pred_inverse\n",
    "    })\n",
    "\n",
    "    print(\"\\nðŸ“Š Káº¿t quáº£ dá»± bÃ¡o nhiá»‡t Ä‘á»™ (T2M):\")\n",
    "    print(pred_df.head(24))\n",
    "\n",
    "    # Váº½ biá»ƒu Ä‘á»“\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(pred_df[\"date\"], pred_df[\"T2M_predicted\"], label=\"Dá»± bÃ¡o T2M (Â°C)\")\n",
    "    plt.title(\"ðŸŒ¤ Dá»± bÃ¡o Nhiá»‡t Ä‘á»™ 24 giá» tá»›i\")\n",
    "    plt.xlabel(\"Thá»i gian\")\n",
    "    plt.ylabel(\"Nhiá»‡t Ä‘á»™ (Â°C)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # LÆ°u káº¿t quáº£\n",
    "    pred_df.to_csv(\"forecast_T2M_result.csv\", index=False)\n",
    "    print(\"ðŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ -> forecast_T2M_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21bda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¡ Äang táº£i dá»¯ liá»‡u NASA POWER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7364/3152177213.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_date = dt.datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dá»¯ liá»‡u NASA: (1104, 12)\n",
      "ðŸ“¦ ÄÃ£ load scaler huáº¥n luyá»‡n.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mforecast_T2M\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mforecast_T2M\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m     scaler.fit(df[FEATURES])\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Scale & táº¡o input\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df_scaled, _ = \u001b[43mpreprocess_features\u001b[49m(df, scaler)\n\u001b[32m     19\u001b[39m X_input = make_input_sequence(df_scaled)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocess_features' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    forecast_T2M()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
