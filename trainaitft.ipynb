{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     TimeSeriesDataSet,\n\u001b[32m      7\u001b[39m     TemporalFusionTransformer,\n\u001b[32m      8\u001b[39m     GroupNormalizer\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_forecasting import (\n",
    "    TimeSeriesDataSet,\n",
    "    TemporalFusionTransformer,\n",
    "    GroupNormalizer\n",
    ")\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from lightning import Trainer, LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherChunkDataset(Dataset):\n",
    "    def __init__(self, filepath, chunk_size=200000):\n",
    "        self.filepath = filepath\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunks = self._count_chunks()\n",
    "\n",
    "    def _count_chunks(self):\n",
    "        total = sum(1 for _ in pd.read_csv(self.filepath, chunksize=self.chunk_size))\n",
    "        print(f\"🧩 Tổng số chunk: {total}\")\n",
    "        return total\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.chunks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        reader = pd.read_csv(self.filepath, chunksize=self.chunk_size, parse_dates=[\"date\"])\n",
    "        for i, chunk in enumerate(reader):\n",
    "            if i == idx:\n",
    "                df = chunk.copy()\n",
    "                cols = [\"date\",\"T2M\",\"QV2M\",\"PS\",\"WS10M\",\"PRECTOTCORR\",\n",
    "                        \"CLRSKY_SFC_SW_DWN\",\"Latitude\",\"Longitude\",\n",
    "                        \"hour\",\"day\",\"month\",\"season\"]\n",
    "                df = df[cols].dropna()\n",
    "\n",
    "                df[\"location\"] = df[\"Latitude\"].astype(str) + \"_\" + df[\"Longitude\"].astype(str)\n",
    "                df[\"time_idx\"] = (df[\"date\"] - df[\"date\"].min()).dt.total_seconds() // 3600\n",
    "                df[\"time_idx\"] = df[\"time_idx\"].astype(int)\n",
    "                return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tft_from_chunk(df_chunk):\n",
    "    max_encoder_length = 24 * 30\n",
    "    max_prediction_length = 24 * 7\n",
    "\n",
    "    training_cutoff = df_chunk[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        df_chunk[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"T2M\",\n",
    "        group_ids=[\"location\"],\n",
    "        min_encoder_length=max_encoder_length // 2,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_reals=[\"Latitude\", \"Longitude\"],\n",
    "        time_varying_known_reals=[\"hour\",\"day\",\"month\"],\n",
    "        time_varying_unknown_reals=[\n",
    "            \"T2M\",\"QV2M\",\"PS\",\"WS10M\",\"PRECTOTCORR\",\"CLRSKY_SFC_SW_DWN\"\n",
    "        ],\n",
    "        target_normalizer=GroupNormalizer(groups=[\"location\"]),\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        allow_missing_timesteps=True,\n",
    "    )\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, df_chunk, predict=True, stop_randomization=True)\n",
    "\n",
    "    train_loader = training.to_dataloader(train=True, batch_size=64, num_workers=0)\n",
    "    val_loader = validation.to_dataloader(train=False, batch_size=64, num_workers=0)\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=1e-3,\n",
    "        hidden_size=32,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.2,\n",
    "        hidden_continuous_size=16,\n",
    "        loss=QuantileLoss(),\n",
    "        log_interval=10,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    return tft, train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFTLightning(LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super().__init__()\n",
    "        self.model = tft_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.model.training_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.model.validation_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d102da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số chunk đọc được: 9\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_forecasting.models.temporal_fusion_transformer.attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m last_ckpt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 🔧 PATCH FIX: ép mask và attention tensor về cùng device\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_forecasting\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtemporal_fusion_transformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpretableMultiHeadAttention\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(InterpretableMultiHeadAttention, \u001b[33m\"\u001b[39m\u001b[33m_patched_device_fix\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     14\u001b[39m     old_forward = InterpretableMultiHeadAttention.forward\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pytorch_forecasting.models.temporal_fusion_transformer.attention'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filepath = \"datatrainai_5_years_clean.csv\"\n",
    "    dataset = WeatherChunkDataset(filepath, chunk_size=200_000)\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    last_ckpt = None\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        print(f\"\\n🚀 Huấn luyện chunk {i+1}/{len(dataset)} ...\")\n",
    "        df_chunk = dataset[i]\n",
    "\n",
    "        tft, train_loader, val_loader = create_tft_from_chunk(df_chunk)\n",
    "        tft = TFTLightning(tft)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            max_epochs=5,\n",
    "            log_every_n_steps=10\n",
    "        )\n",
    "\n",
    "        if last_ckpt and os.path.exists(last_ckpt):\n",
    "            print(f\"🔁 Tiếp tục huấn luyện từ {last_ckpt}\")\n",
    "            trainer.fit(tft, ckpt_path=last_ckpt,\n",
    "                        train_dataloaders=train_loader,\n",
    "                        val_dataloaders=val_loader)\n",
    "        else:\n",
    "            trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "        ckpt_path = f\"checkpoints/tft_weather_chunk_{i+1}.ckpt\"\n",
    "        trainer.save_checkpoint(ckpt_path)\n",
    "        last_ckpt = ckpt_path\n",
    "        print(f\"✅ Đã lưu checkpoint: {ckpt_path}\")\n",
    "\n",
    "    print(\"\\n🎉 HUẤN LUYỆN HOÀN TẤT (GPU OK, PYTHON 3.12) 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf170308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
